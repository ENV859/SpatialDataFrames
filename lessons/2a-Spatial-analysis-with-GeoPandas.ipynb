{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analysis with GeoPandas\n",
    "ENV 859 - Fall 2024  \n",
    "© John Fay, Duke University\n",
    "\n",
    "In this notebook, we examine how GeoPandas is used in peforming a spatial analysis. We take an example of looking at the demographic characteristics of where electric vehicle (EV) charging stations have been located in Durham, Wake, and Orange counties with respect to 2010 Census and Social Vulnerability Index values. (It's not a very sensible analysis as done here, but we are concentrating on the mechanics more than the utility of the analysis...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Objectives:\n",
    "* Executing a \"***data science workflow***\" with a GeoPandas\n",
    " - Read data into a geodataframe (CSV and GeoJSON)\n",
    " - Explore the data: columns/column types, summaries, plots\n",
    " - Analyze the data...\n",
    " - Visualize results\n",
    "* **Subseting features** in a geodataframe by attribute\n",
    "* **Merging** geodataframes\n",
    "* **Dissolving** geodataframe features based on an attribute value\n",
    "* **Joining attributes** to a geodataframe\n",
    "* **Spatially joining** data from one geodataframe to another\n",
    "* Generating various **plots** from single and multiple geodataframes\n",
    "* **Saving** a geodataframe to a feature class "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow:\n",
    "* [**Part 1: Fetching and Exploring Data**](#Part-1:-Fetching-and-Exploring-the-Data)\n",
    "    * 1.1 Import packages\n",
    "    * 1.2 Read CSV data into geodataframe\n",
    "    * 1.3 Explore the data in the geodataframe\n",
    "    * 1.4 Import census data to geodataframe via web service\n",
    "* [**Part 2: Analysis (and Visualization)**](#Part-2:-The-Analysis-(and-Visualization))\n",
    "    * 2.1 Subset EV features by attribute\n",
    "    * 2.2 Merge the three county geodataframes into a single geodataframe\n",
    "    * 2.3 Dissolve block features to the tract level\n",
    "    * 2.4 Import and join the social vulnerability data to tract features\n",
    "    * 2.5 Compute population density for each tract\n",
    "    * 2.6 Subset EV stations spatially\n",
    "    * 2.7 Spatially join tract attributes to EV features\n",
    "* [**Part 3: Share Results**](#Part-3.-Share-results)\n",
    "    * 3.1 Share your notebook as html or on GitHub\n",
    "    * 3.2 Explot your geodataframe(s) as feature classes or CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Fetching and Exploring the Data\n",
    "Here we'll gather and explore the data we'll be using in our analysis. This includes two datasets. First is the list of EV Charging locations, stored as a CSV file in our data folder. This dataset has coordinate columns that we'll use to construct points and convert into a geodataframe as we learned in our previous lessons. \n",
    "\n",
    "The second dataset is comprised of 2010 Census BlockGroup data for all of North Carolina. We'll fetch these data from an on line resource using a web service. We'll revisit how web services later; for now, we'll use this process to fetch data for three counties: Durham, Wake, and Orange. \n",
    "\n",
    "For each dataset, we'll get the data into geodataframe format and then explore the data in various ways. Then we'll move to Part 2 where we analyse the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1: Import packages needed in the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Command to run if autocomplete is slooooowwww\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4 style=\"color:red\">♦ Knowledge Check ♦</H4>  \n",
    "\n",
    "_→ Can you explain what role each package imported might do in our analysis?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2: Create a geodataframe from a CSV file\n",
    "As done in a previous notebook, we want to:\n",
    "* Import a CSV file containing coordinate columns into a Pandas dataframe,\n",
    "* Create a collection of Shapely points from the coordinate fields, and \n",
    "* Create a geodataframe from the components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in charging stations CSV, convert to geodataframe\n",
    "df = \n",
    "\n",
    "#Create the geoseries from the X and Y columns\n",
    "geom = \n",
    "\n",
    "#Convert to a geodataframe, setting the CRS to WGS 84 (wkid=4326)\n",
    "gdf_stations_all = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3: Explore the data in geodataframe\n",
    "Have a quick look at the contents imported. Things to check include:\n",
    "* How many rows and columns were imported\n",
    "* The names, data types, and number of non-null values in each column\n",
    "* Examine a single record from the geodataframe\n",
    "* What geometry types are included in the geodataframe?\n",
    "* Summary statistics of numeric columns, if applicable\n",
    "* Correlations among column values, if applicable\n",
    "* Spatial plot of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sow the number rows and columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examine the structure of the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examine a single record of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reveal the geometry type(s) contained inthe geodataframae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3 style=\"color:red\">♦ Knowledge Check ♦</H3>\n",
    "\n",
    "→ _Could you performm the same steps of importing and exploring the USGS gage locations in NC stored in the CSV file `../data/gages.csv`?_\n",
    " * Convert data to a geodataframe: `gdf_gages`\n",
    " * Explore the data\n",
    " * Plot the gage sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 1.4. Import NC Census Block Group features via NC OneMap's web service\n",
    "_We will explore web services a bit later, but we'll use the code below to acquire polygon data of census block groups for Durham, Wake, and Orange counties from an NC OneMap Web Service. Once imported, we'll merge these geodataframes together and use them in our subsequet analyses._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First, to simplify matters, I've created a Python function to fetch data for a specific county given its FIPS code.  \n",
    "(*We'll examine how this works a bit later...*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to read NCOneMap feature services into a geodataframe\n",
    "def getBlockGroupData(FIPS):\n",
    "    #Construct the url from the function arguments\n",
    "    url=f'https://services.nconemap.gov/secure/rest/services/NC1Map_Census/FeatureServer/8/query?' + \\\n",
    "        f\"where=GEOID10+LIKE+'{FIPS}%'&outFields=GEOID10,TOTAL_POP&f=geojson\"\n",
    "    \n",
    "    #Create a geodataframe from the URL\n",
    "    gdf = gpd.read_file(url)\n",
    "    \n",
    "    #Return the geodataframe\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now, we apply that function for the three counties we want to examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch census block groups for Durham, Orange, and Wake counties using the above function\n",
    "gdf_DurmBlkGroups = getBlockGroupData(37063)\n",
    "gdf_WakeBlkGroups = getBlockGroupData(37183)\n",
    "gdf_OrangeBlkGroups = getBlockGroupData(37135)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _Challenge: See if you can fetch Chatham county block groups (FIPS = 37037)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Challenge: See if you can fetch Chatham county block groups (FIPS = 37037)\n",
    "gdf_Chatam = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Explore** the data...\n",
    " * What is its coordinate reference system?\n",
    " * What columns are included?\n",
    " * What does the first record look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the Durham block group geodataframe's coordinate reference system\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore the Durham block group geodataframe's columns...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examine a sample record from the geodataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Visualize** the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Durham's population, setting the colormap to \"viridis\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the block groups for all three counties\n",
    "\n",
    "#First, plot one geodataframe, saving the output as \"thePlot\"\n",
    "\n",
    "\n",
    "#Plot another geodataframe, telling it to use the axes in \"thePlot\" created above\n",
    "\n",
    "\n",
    "#Repeat...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: The Analysis (and Visualization)\n",
    "Now that we've obtained a few datasets and got them into geodataframes, we'll perform some analysis. These include:\n",
    "* Subsetting the EV charging stations for those in specific cities.\n",
    "* Identifying the census blocks surrounding each EV station, within a distance of 1km\n",
    " * To do this, we'll merge the Durham, Wake, and Orange Co block data selected above\n",
    " * Then we'll buffer our selected EV station points a distance of 1km\n",
    " * And finally, we'll select blocks that intersect the EV station buffers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1: Subset the EV Station points based on attribute values\n",
    "Doc: https://geopandas.org/indexing.html\n",
    "\n",
    "Subsetting features in a geodataframe uses the same methods as subsetting recordsin a Pandas dataframe. Here we'll run through an example by subsetting EV stations found oly within Durham, Raleigh, and Chapel Hill. \n",
    "\n",
    "* **2.1.1** Examine unique values in the `City` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reveal the unique values in the City column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **2.2.2** Subset records for those where the City is \"Durham\", \"Raleigh\", or \"Chapel Hill\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset records where the City is \"Durham\", \"Raleigh\", or \"Chapel Hill\"\n",
    "gdf_stations = \n",
    "gdf_stations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recall, an alternative is to use masks...\n",
    "gdf_stations = \n",
    "gdf_stations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another, more efficient mask using `isin`\n",
    "gdf_stations = \n",
    "gdf_stations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **2.1.3** Explore the results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the results\n",
    "gdf_stations.plot(\"City\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot them with a base map (using Contextily - more later...)\n",
    "city_plot = gdf_stations.to_crs(3857).plot(column=\"City\",figsize=(10,10),alpha=0.6)\n",
    "ctx.add_basemap(city_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2: Merge the 3 county block group geodataframes into one\n",
    "Doc: https://geopandas.org/mergingdata.html\n",
    "1. Check that all data have the same crs\n",
    "1. Optionally, add a field to identify the source geodataframe\n",
    "1. Apply the `append()` function\n",
    "1. Check/explore the result\n",
    "\n",
    "We'll start by appending the Wake Co. dataset to the Durham Co. one. Then you will append the Orange Co. dataframe to that product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **2.2.1** Check that the two files share the same coordinate reference system  \n",
    " →*If the were different, we could use `to_crs()` to transform one dataset to use the crs of the other*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the crs of the two geodataframes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **2.2.2** Add an identifying column to the source geodataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a field to each input, setting values to identify the source dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **2.2.3** Append one dataframe to the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append the Wake Co features to the Durham Co features,\n",
    "gdf_BlkGrp_step1 = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **2.2.4** Explore the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check to see that the total rows in the merged gdf match the sum of the two component gdfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<H4 style=\"color:red\">♦ TASK ♦</H4>\n",
    "\n",
    "_Append the Orange Co blockgroup features to the `gdf_BlkGrp_step` geodataframe we just created._  \n",
    "\n",
    "**Remember to:**\n",
    "* check that the coordinate refernce systems are the same, and \n",
    "* add a new column to the `gdf_OrangeBlkGroups`, setting its value to the County name.\n",
    " \n",
    "→ Save the result as `gdf_BlkGrps`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check that the coordinate refernce systems are the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the county field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append the geodataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.3: Dissolve block features to the tract level\n",
    "We have Social Vulnerability Data to examine in our analysis, but these data are at the Tract, not BlockGroup level. Thus, to join these attributes to our geodataframe, we'll need to aggregate our blockgroups to the tract level. Fortunately, the `GEOID10` attribute is structured such that the census tract is just the first 11 characters. So we will create a new column holding these first 11 characters, and then we'll dissolve our blockgroup features sharing the same tract ID to single features.\n",
    "\n",
    "Doc: https://geopandas.org/aggregation_with_dissolve.html\n",
    "* First, create a new column listing tract IDs (the first 11 digits of the GEOID10)\n",
    "* Dissolve the features on this attribute, computing aggregate sum of the TOTAL_POP field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **2.3.1** Create the Tract column from the GEOID10 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the Tract column\n",
    "gdf_BlkGrp['TRACT']=\n",
    "gdf_BlkGrp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **2.3.2** Disslve features on the Tract column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dissolve features on tract, computing summed population\n",
    "gdf_Tract =\n",
    "\n",
    "#Show the results\n",
    "gdf_Tract.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4: Import the Social Vulnerability Data and join with the Tract features\n",
    "Now that we have the data at the tract level, we can join the Social Vulnerability Index data, stored in a CSV file (`./data/NC_SVI_2018.csv`).\n",
    "\n",
    "Doc: https://geopandas.org/mergingdata.html#attribute-joins\n",
    "* Import the SVI data as a Pandas dataframe\n",
    "* Append records from the SVI dataframe to the Tracts geodataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **2.4.1** Import and explore the SVI data into a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and explore the SVI data\n",
    "df_SVI = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Challenge**:<br>→ _Modify the `read_csv()` command above so that 'ST' and 'STCNTY' are also imported as strings._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot a histogram of the SVI values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><font color='red'> Whoops!!! </h3>\n",
    "Values should be between 0 and 1, but we see in the histogram that a few value are down near -1000. Turns out a few records have SVI values of -999. We need to remove those records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a mask of values greater than or equal to zero\n",
    "\n",
    "#Apply that mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the histogram again\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Phew! Exploring the data payed off!_\n",
    "\n",
    "* **2.4.2** Append the dataframe to the tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Have a look at the merge command syntax\n",
    "gdf_Tract.merge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join the SVI data to the tract features\n",
    "gdf_Tract_joined = \n",
    "\n",
    "#Examine the output\n",
    "gdf_Tract_joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore the output, look form null values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Looks like we have some features missing SVI data. Let's examine those more closely._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a mask of null SVI values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We can either assign a value to these missing values or leave them as no data. We'll just leave them blank for now..._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5: Compute Population Density for Each Tract\n",
    "Our combined dataframes have a field indicating the total population in each block group. We want to compute population density from this and from the area of each tract. We don't yet have an area field in our dataframe, but we can compute that from our spatial features. But before we can do this, we need to transform our data into a projected coordinate system. So... the steps for this analysis include:\n",
    "* Transform the dataframe to a projected coordinate system (UTM Zone 17N)\n",
    "* Compute a new `Area_km2` column in our dataframe\n",
    "* Compute a new `PopDens` column in our dataframe by dividing `TOTAL_POP` by `Area_km` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **2.5.1** Transform the dataframe to a projected coordinate system (UTM Zone 17N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Project the data to UTM Zone 17N (EPSG 32617)\n",
    "gdf_Tract_utm = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **2.5.2** Compute a new `Area_km2` column in our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute a new column of geometry area (in sq km)\n",
    "gdf_Tract_utm['Area_km2'] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **2.5.3** Compute a new `PopDens` column in our dataframe by dividing `TOTAL_POP` by `Area_km` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute a new column of population density\n",
    "gdf_Tract_utm['PopDens'] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **2.5.4** Explore the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the distribution of areas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot a map of log tranformed population density\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _**2.5.5** Log transform the data to improve the visualization_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log transform the pop_dens data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the log-transformed distribution of areas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot a map of log tranformed population density\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6: Subset EV stations spatially\n",
    "Doc: https://geopandas.org/set_operations.html  \n",
    "Previously, we subset EV stations by an attribute (City). Here we'll see how we can instead select features spatially. We do this with GeoPanda's **Overlay** operations.\n",
    "\n",
    "**To spatially select features**:\n",
    "* Ensure both datasets share the same coordinate reference system; transform if needed\n",
    "* Use the `overlay`:`intersection` operation to select EV features overlap with the Tracts dataset\n",
    "* Examine the outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **2.6.1** Ensure both datasets share the same crs; transform if not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensure both datasets share the same crs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Project one dataset to match the other\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot points on tracts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **2.6.2** Select EV stations that intersect the county features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intersect the two dataframes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **2.6.3** Examine the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the data\n",
    "\n",
    "#Construct the first (lowest layer) of the data to plot, saving it as \"the_plot\"\n",
    "the_plot = gdf_Tract_utm.plot(\n",
    "    color='lightgrey', #Set the fill of the Tract features\n",
    "    edgecolor='grey',  #Set the edge color...\n",
    "    alpha=0.4,         #Set the transparency...\n",
    "    figsize=(12,12))   #Set the size of the figure\n",
    "\n",
    "#Plot the stations, setting them to share the axes of \"the_plot\"\n",
    "gdf_stations_select.plot(\n",
    "    ax=the_plot,        #Draw it on the plot created above\n",
    "    column='City',      #Color the features by values in the City column\n",
    "    markersize=45,      #Set the size of the markers\n",
    "    edgecolor='white'); #Set the edge color of the markers\n",
    "\n",
    "#Use Contextily to add a nice backdrop\n",
    "ctx.add_basemap(\n",
    "    ax = the_plot,         #Add it to our existing plot \n",
    "    crs=gdf_Tract_utm.crs, #Transform the background to match the data's crs\n",
    "    source=ctx.providers.CartoDB.Voyager) #Set the type of backdrop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7: Spatially join tract attributes to EV features\n",
    "Doc: https://geopandas.org/mergingdata.html#spatial-joins\n",
    "\n",
    "Now that we have a proper susbset of EV stations, let's add demographic data to our EV locations by peforming a spatial join with the tract geodataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **2.7.1** Ensure the datasets involved share the same coordinate reference system  \n",
    "_→ What would happen if we made a typo and only included a single equals sign??_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare crs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **2.7.2** Execute the spatial join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute the spatial join\n",
    "gdf_JoinedData = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **2.7.3** Explore the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the data\n",
    "gdf_JoinedData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot\n",
    "the_plot = gdf_Tract_utm.plot(\n",
    "    color='lightgrey',\n",
    "    edgecolor='grey',\n",
    "    alpha=0.4,\n",
    "    figsize=(12,12))\n",
    "\n",
    "gdf_JoinedData.plot(\n",
    "    ax=the_plot,\n",
    "    column='SVI_ev',\n",
    "    markersize=60,\n",
    "    edgecolor='white');\n",
    "\n",
    "ctx.add_basemap(\n",
    "    ax=the_plot, \n",
    "    crs=gdf_Tract_utm.crs,\n",
    "    source=ctx.providers.CartoDB.Voyager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make some graphical plots\n",
    "ax=pd.DataFrame(gdf_JoinedData).boxplot(\n",
    "    column='SVI_ev',\n",
    "    by='City',\n",
    "    rot=45,\n",
    "    figsize=(19,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Share results\n",
    "With this document we now have a fully reproducible analytic workflow, complete with visualizations of our result. We can export this notebook as an HTML document and share that, or if we commit this document to our GitHub account and share the link to that notebook. \n",
    "\n",
    "### 3.1: Sharing your notebook\n",
    "\n",
    "* **3.1.1**\n",
    " * Export your completed notebook as an HTML document. \n",
    " * View it in a web browser\n",
    " \n",
    "* **3.1.2**\n",
    " * Commit the changes to your forked repository\n",
    " * Navigate to https://nbviewer.jupyter.org/ and paste your repository's URL\n",
    " * Share this link with others..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also save the resulting geodataframes as feature classes for more analysis, either in Python or in ArcGIS Pro. \n",
    "\n",
    "### 3.2: Exporting the geodataframe\n",
    "We can export our `gdf_JoinedData` geodataframe easily,either as a shapefile or a CSV file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **3.2.1** Export the final geodataframe to a feature class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export the geodataframe to a shapefile\n",
    "gdf_JoinedData.to_file(\n",
    "    filename='../data/EV_sites_with_data.shp',\n",
    "    driver='ESRI Shapefile',\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **3.2.2** Export the final geodataframe to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export the geodataframe to a CSV file\n",
    "pd.DataFrame(gdf_JoinedData).to_csv(\n",
    "    '../data/my_saved_data.csv',\n",
    "    index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

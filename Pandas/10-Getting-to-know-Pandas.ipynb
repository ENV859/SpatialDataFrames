{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Pandas?\n",
    "One of the best options for working with tabular data in Python is to use the [Python Data Analysis Library](http://pandas.pydata.org/) (a.k.a. Pandas). The Pandas library provides data structures, produces high quality plots with [matplotlib](http://matplotlib.org/) and integrates nicely with other libraries that use [NumPy](http://www.numpy.org/) arrays.\n",
    "\n",
    "Like `NumPy`, Pandas introduces some new data types to our Python world, the most important of which is the **DataFrame**. \n",
    "\n",
    "Briefly, a DataFrame is a 2-dimensional data structure that can store data of different types (including characters, integers, floating point values, factors and more) in columns. It is similar to a spreadsheet or an SQL table or the data.frame in R. A DataFrame always has an index (0-based). An index refers to the position of an element in the data structure.\n",
    "\n",
    "Once we load our data into a DataFrame, pandas gives a host of analytical capabilities with the data. Among these are:\n",
    "  - Generate quick data summaries and data descriptions\n",
    "  - Subset/select/query specific rows and/or columns of data\n",
    "  - Handle missing data\n",
    "  - Group/aggregate data based on one or more common attributes\n",
    "  - Sort, transform, pivot, and \"melt\" data into new data structures\n",
    "  - Merge, join, and concatenate data from different dataframes into a single dataframe \n",
    "  - Plot data\n",
    "  \n",
    "In short, Pandas and its DataFrame object is essentially a one-stop for anything data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning by Diving In!\n",
    "Here in this notebook, we'll dive in with some examples and then explain what's going on. The highlights here include:\n",
    "* Creating DataFrames programmatically and then by reading in data; and in doing so reviewing the structure and key elements of a DataFrame\n",
    "* Examining key properties and methods of a DataFrame that quickly reveal information about our DataFrame: the number of rows and columns, what types of data it stores, quick summary statistics, etc.\n",
    "* Summarizing the data in a DataFrame, including how to quickly count and list unique items in a column.\n",
    "* Examining the various ways to handle missing data in a DataFrame\n",
    "* Grouping data\n",
    "* Subsetting observations (rows) and variables (columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It all starts by importing the package..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the package\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The DataFrame\n",
    "We'll begin by exploring the key elements of the DataFrame object. Some notions are self evident, i.e., data are stored in rows and columns, much like a spreadsheet. Others are more nuanced: implicit and explicit indices, tables vs. views, and some others.\n",
    "\n",
    "Let's begin examining the components of DataFrames by examining two ways they can be created.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame as a list of lists\n",
    "First, a DataFrame can be considered as a list of lists. Below we see an example where we have 4 sub-lists, each containing 3 items (e.g. the first list [`'Joe'`,`22`,& `True`]). Each of these 4 sub-lists comprises a row in the resulting DataFrame, and each item in a given list becomes a column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a simple data frame as a list of lists\n",
    "df = pd.DataFrame([['Joe',22,True],\n",
    "                   ['Bob',25,False],\n",
    "                   ['Sue',28,False],\n",
    "                   ['Ken',24,True]],\n",
    "                  index = [10,20,40,30],\n",
    "                  columns = ['Name','Age','IsStudent']\n",
    "                 )\n",
    "#Display the resulting data frame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few key points here: \n",
    "* First is that each of the sub-lists has the same number of elements (3) and the same data types as the other sub-lists. Otherwise we'd end up with missing data or \"coerced\" data types.\n",
    "* Second is that we also explicitly specify and **index** for the rows (`index = [1,2,3,4]`). The index allows us to identify a specific row.\n",
    "* Likewise, we explicitly set column names with `columns = ['Name','Age','IsStudent']`, and yes, these allow us to indentify specific columns in our DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data frame as a collection of dictionaries\n",
    "Another way to build (and think of) a DataFrame as a set of dictionaries where each dictionary is a column of data, with the dictionary's key being the column name and it's value being a list of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a data frame as dictionaries of lists\n",
    "df = pd.DataFrame({\"Name\":['Joe','Bob','Sue','Ken'],\n",
    "                   \"Age\":[22,25,28,24],\n",
    "                   \"IsStudent\":[True,False,False,True]},\n",
    "                  index = [10,20,40,30]\n",
    "                 )\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the order of columns has changed (they are alphabetized), the data are the same as the previous DataFrame even though it was created differently. This is just another way to think of the data underlying a DataFrame.\n",
    "\n",
    "Of note here is that each dictionary has the same number of elements in it and the order of the elements is important otherwise the values in one dictionary/column would lose its proper correspondence with the other elements. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meh, so what...\n",
    "What does this reveal? List of lists vs set of dictionaries? Well, it explains how you can extract elements from the DataFrame. Thinking of a DataFrame as a list of list, getting the value of the 2nd column, 3rd row is equivalent of getting data from the 2nd item in the 3rd list.  \n",
    "\n",
    "We can get that value using the DataFrame's `iloc` function (short for intrinsic location), passing the row and column of the location we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the 2nd item from the 3rd row; recalling Python is zero-based\n",
    "df.iloc[2,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we hop over to thinking a DataFrame is a set of dictionaries, we can target a specific value by specifying the index of the value (row) from the dictionary column) we want. The row however, is referred to by the index *we* assigned, not it's implicit index generated by the order in which it was entered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the value in the 'Name' column corresponding to the row with an index of '20'\n",
    "df['Name'][20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also to quick math on our data. If we wanted to calculate the age of our students in days: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age_days'] = df['Age'] * 365\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We'll return to how we extract data from a DataFrame, but for now just soak in the fact that values in a DataFrame can be referenced by their implicit location (i.e. their row, column coordinates) and by their explicit column name and row index._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Creating a dataframe from a CSV file\n",
    "More than likely we'll be reading in data vs entering it manually, so let's review how files are read into a Pandas Dataframe. Pandas can read many other formats: Excel files, HTML tables, JSON, etc. But let's concentrate on the simplest one - the csv file - and discuss the key parameters involved. \n",
    "\n",
    "In the Data folder within our workspace is a file named `surveys.csv` which holds the data we'll use. If you're curious, this dataset is part of the Portal Teaching data, a subset of the data from Ernst et al [Long-term monitoring and experimental manipulation of a Chihuahuan Desert ecosystem near Portal, Arizona, USA](http://www.esapubs.org/archive/ecol/E090/118/default.htm).\n",
    "\n",
    "The dataset is stored as a `.csv` file: each row holds information for a single animal, and the columns represent:\n",
    "\n",
    "| Column | Description |\n",
    "| :--- | :--- |\n",
    "|record_id |\tUnique id for the observation |\n",
    "|month| \tmonth of observation |\n",
    "|day |\tday of observation |\n",
    "|year |\tyear of observation |\n",
    "|plot_id |\tID of a particular plot |\n",
    "|species_id |\t2-letter code |\n",
    "|sex |\tsex of animal (“M”, “F”) |\n",
    "|hindfoot_length |\tlength of the hindfoot in mm |\n",
    "|weight |\tweight of the animal in grams |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we read in this file, saving the contents to the variabel `surveys_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the surveys.csv file\n",
    "surveys_df = pd.read_csv('../data/surveys.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Exploring our Species Survey DataFrame\n",
    "Now, as we often do, let's look at the type of the object we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the object type of the object we just created\n",
    "type(surveys_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, it’s a \"DataFrame\" (or, to use the full name that Python uses to refer to it internally, a `pandas.core.frame.DataFrame`).\n",
    "\n",
    "→ What kinds of data does our data frame contain? DataFrames have an attribute called `dtypes` that answers this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the data types of the columns in our data frame\n",
    "surveys_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_All the values in a column have the same type._ For example, months have type `int64`, which is a kind of integer. Cells in the month column cannot have fractional values, but the weight and hindfoot_length columns can, because they have type `float64`. The `object` type doesn’t have a very helpful name, but in this case it represents strings (such as ‘M’ and ‘F’ in the case of sex)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print the entire contents of the data frame by just calling the object.\n",
    "\n",
    "*Remember that in Jupyter notebooks, we can toggle the output by clicking the lightly shaded area to the left of it...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the data frame's contents\n",
    "surveys_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the bottom of the [long] output above, we see that the data includes 33,549 rows and 9 columns. \n",
    "\n",
    "The first column is the **index** of the DataFrame. The index is used to identify the position of the data, but it is not an actual column of the DataFrame. It looks like the `read_csv` function in Pandas read our file properly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the values in a column have the same type. For example, months have type `int64`, which is a kind of integer. Cells in the month column cannot have fractional values, but the weight and hindfoot_length columns can, because they have type `float64`. The `object` type doesn’t have a very helpful name, but in this case it represents strings (such as ‘M’ and ‘F’ in the case of sex)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Additional useful DataFrame properties\n",
    "There are many ways to summarize and access the data stored in DataFrames, using attributes and methods provided by the `DataFrame` object.\n",
    "\n",
    "To access an <u>attribute</u>, use the DataFrame object name followed by the attribute name `df_object.attribute`. Using the DataFrame `surveys_df` and `attribute` columns, an index of all the column names in the DataFrame can be accessed with `surveys_df.columns`.\n",
    "\n",
    "<u>Methods</u> are called in a similar fashion using the syntax `df_object.method()`. As an example, `surveys_df.head()` gets the first few rows in the DataFrame `surveys_df` using the `head()` method. With a method, we can supply extra information in the parens to control behaviour.\n",
    "\n",
    "Let’s look at the data using these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <font color='red'>*Exercise* - DataFrames</font>\n",
    "Using our DataFrame `surveys_df`, try out the attributes & methods below to see what they return.\n",
    "1. `surveys_df.columns`\n",
    "1. `surveys_df.shape`    Take note of the output of shape - what format does it return the shape of the DataFrame in?\n",
    "1. `surveys_df.head()`   Also, what does surveys_df.head(15) do?\n",
    "1. `surveys_df.tail()`\n",
    "\n",
    "*Use the boxes below to type in the above commands and see what they produce.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 1\n",
    "surveys_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Inspecting the Data in a Pandas DataFrame\n",
    "We’ve read our data into Python. Next, let’s perform some quick summary statistics to learn more about the data that we’re working with. We might want to know how many animals were collected in each plot, or how many of each species were caught. We can perform summary stats quickly using groups. But first we need to figure out what we want to group by.\n",
    "\n",
    "Let’s begin by exploring the data in our data frame:\n",
    "\n",
    "First, examine the column names. (Yes,I know we just did that in the Challenge above...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the column names\n",
    "surveys_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract one column of data into a new object by referencing that column as shown here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speciesIDs = surveys_df['species_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the type of this `speciesIDs` object reveals another Pandas data type: the *Series* which is slightly different than a DataFrame..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(speciesIDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `series` object is a one-dimensional array, much like a NumPy array, with its own set of properties and functions. The values are indexed allowing us to extract values at a specific row (try: `speciesIDs[5]`) or slice of rows (try: `species[2:7]`). \n",
    "\n",
    "We can also, using the `series.nunique()` and `series.unique()` functions, generate a count of unique values in the series and a list of unique values, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reveal how many unique species_ID values are in the table\n",
    "speciesIDs.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List the unique values\n",
    "speciesIDs.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <font color='red'>*Challenge* - Counts and Lists from Data </font>\n",
    "\n",
    "\n",
    "1. Create a list of unique plot ID’s found in the surveys data (much like we did above with the species id values). Call it `plot_names`. How many unique plots are there in the data? How many unique species are in the data?\n",
    "\n",
    "1. What is the difference between `len(plot_names)` and `surveys_df['plot_id'].nunique()`?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Grouping Data in Pandas\n",
    "We often want to calculate summary statistics grouped by subsets or attributes within fields of our data. For example, we might want to calculate the average weight of all individuals _per plot_.\n",
    "\n",
    "We can calculate basic statistics for all records in a single column using the syntax below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df['weight'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also extract one specific metric if we wish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Min: \", surveys_df['weight'].min())\n",
    "print(\" Max: \", surveys_df['weight'].max())\n",
    "print(\" Mean: \", surveys_df['weight'].mean())\n",
    "print(\" Std Dev: \", surveys_df['weight'].std())\n",
    "print(\" Count: \", surveys_df['weight'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we want to summarize by one or more variables, for example sex, we can use Pandas’ `.groupby` method. Once we’ve created a groupby DataFrame, we can quickly calculate summary statistics by a group of our choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by sex\n",
    "grouped_data = surveys_df.groupby('sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show just the grouped means\n",
    "grouped_data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or, use the describe function to reveal all summary stats for the grouped data\n",
    "grouped_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <font color='red'>Challenge - Summary Data </font>\n",
    "1. How many recorded individuals are female `F` and how many male `M`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 1: Show the *count* of records, grouped by sex\n",
    "grouped_data.█()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The statement above produces another dataframe. Show just the count of the records in the `weight` field in the resulting dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challege 2: Just show the 'weight' column in the above statement\n",
    "grouped_data.█()['█']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. What happens when you group by two columns using the following syntax and then grab mean values:\n",
    " * `grouped_data2 = surveys_df.groupby(['plot_id','sex'])`\n",
    " * `grouped_data2.mean()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Display a summary of **hindfood length** values for each **plot id** in your data. _HINT: First group data, then extract the one variable you want to summarize, and finally use the `describe` function on that result to compute summary statistics..._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *More complex aggregating functions...*\n",
    "We can also supply a **dictionary of aggregating functions** so that each column in the grouped result is aggregated exactly how we want (i.e. instead of computing just the sum or mean of all columns). This dictionary is built by specifying the <u>column name as the key</u> and the <u>aggregate function(s) as the values</u>. Below is an example to aggregate the data by `sex`, computing the minumum and maximum of the `year`, the median of the `hindfoot_length`, and the mean `weight`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the aggregate function dictionary\n",
    "aggFuncs = {\n",
    "    \"year\": ['count','min','max'],#compute count, min, and max of the year attribute\n",
    "    \"hindfoot_length\": 'median',  #compute the median hindfoot length\n",
    "    \"weight\": 'mean'}             #compute the mean weight\n",
    "#Apply the dictionary\n",
    "surveys_df.groupby('sex').agg(aggFuncs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
